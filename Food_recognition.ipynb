{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1616495368653,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "7UCZm0h1HO6R"
   },
   "outputs": [],
   "source": [
    "#For Downloading the dataset on colab\n",
    "\n",
    "#!wget https://datasets.aicrowd.com/default/aicrowd-public-datasets/food-recognition-challenge/v0.4/test_images-v0.4.tar.gz\n",
    "#!wget https://datasets.aicrowd.com/default/aicrowd-public-datasets/food-recognition-challenge/v0.4/train-v0.4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1255,
     "status": "ok",
     "timestamp": 1616495369080,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "Uu0DGBxGepjo"
   },
   "outputs": [],
   "source": [
    "#!unzip train-v0.4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1244,
     "status": "ok",
     "timestamp": 1616495369082,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "E7chBjpSYt9c"
   },
   "outputs": [],
   "source": [
    "#Extract dataset from the tar files\n",
    "#!for f in *.tar.gz; do tar xf \"$f\"; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5274,
     "status": "ok",
     "timestamp": 1616495435927,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "LwU3ZNa6yhuU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8989,
     "status": "ok",
     "timestamp": 1616495444942,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "ECfFzlb7zi6j",
    "outputId": "e27de67b-6b32-4e6a-b8d2-28bf8539b9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/examples\n",
      "  Cloning https://github.com/tensorflow/examples to /tmp/pip-req-build-i3k9c3bp\n",
      "  Running command git clone -q https://github.com/tensorflow/examples /tmp/pip-req-build-i3k9c3bp\n",
      "Requirement already satisfied: absl-py in ./dl_env/lib/python3.8/site-packages (from tensorflow-examples===c1bdc55b412350c31831777d3d348ba898c87bae-) (0.11.0)\n",
      "Requirement already satisfied: six in ./dl_env/lib/python3.8/site-packages (from tensorflow-examples===c1bdc55b412350c31831777d3d348ba898c87bae-) (1.15.0)\n",
      "Building wheels for collected packages: tensorflow-examples\n",
      "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorflow-examples: filename=tensorflow_examples-c1bdc55b412350c31831777d3d348ba898c87bae_-py3-none-any.whl size=236392 sha256=96252327e652285bc626ddee4e5689c68c71a2ad443733f48a512beaedfe0c37\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-oznnueff/wheels/8d/8c/b3/e1cd9490c019ff39ff4617c1a26c4600d189602fe2aab4aaae\n",
      "\u001b[33m  WARNING: Built wheel for tensorflow-examples is invalid: Metadata 1.2 mandates PEP 440 version, but 'c1bdc55b412350c31831777d3d348ba898c87bae-' is not\u001b[0m\n",
      "Failed to build tensorflow-examples\n",
      "Installing collected packages: tensorflow-examples\n",
      "  Attempting uninstall: tensorflow-examples\n",
      "    Found existing installation: tensorflow-examples 6492d14b42236467bffc573bcb0fe87218f11ec4-\n",
      "    Uninstalling tensorflow-examples-6492d14b42236467bffc573bcb0fe87218f11ec4-:\n",
      "      Successfully uninstalled tensorflow-examples-6492d14b42236467bffc573bcb0fe87218f11ec4-\n",
      "    Running setup.py install for tensorflow-examples ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: tensorflow-examples was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
      "\u001b[?25hSuccessfully installed tensorflow-examples-c1bdc55b412350c31831777d3d348ba898c87bae-\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/tensorflow/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19622,
     "status": "ok",
     "timestamp": 1616495455603,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "zLJsSHb79yB4",
    "outputId": "6434f24e-fb90-4b9f-de49-05ea29f27ee9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AIcrowd/coco.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/AIcrowd/coco.git to /tmp/pip-req-build-ehx3hnj5\n",
      "  Running command git clone -q https://github.com/AIcrowd/coco.git /tmp/pip-req-build-ehx3hnj5\n",
      "Requirement already satisfied: Cython in ./dl_env/lib/python3.8/site-packages (from pycocotools==2.0) (0.29.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/AIcrowd/coco.git#subdirectory=PythonAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 19606,
     "status": "ok",
     "timestamp": 1616495455608,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "hGr3YpDfzTdt"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow_examples.models.pix2pix import pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19288,
     "status": "ok",
     "timestamp": 1616495455610,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "LEC1MZks0pVF",
    "outputId": "1f09a124-3065-4e4f-b456-80858317b41c"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pycocotools import mask as cocomask\n",
    "\n",
    "import os\n",
    "\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_VP07sm1vS8"
   },
   "source": [
    "**Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19317,
     "status": "ok",
     "timestamp": 1616495459382,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "4yBQ76DM19Fa",
    "outputId": "5232e503-f5f9-4cf5-a979-91c748aa7f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.55s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "#Loading the coco annotations\n",
    "folder_loc = \"/home/belericks7/Documenti/deep_learning\"\n",
    "\n",
    "coco_train = COCO(folder_loc + '/train/annotations.json')\n",
    "coco_val = COCO(folder_loc + '/val/annotations.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploring the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 17036,
     "status": "ok",
     "timestamp": 1616495459385,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "51HLAV2QB7op"
   },
   "outputs": [],
   "source": [
    "#to fix\n",
    "\n",
    "def plot_image(image_id):\n",
    "    #read the image\n",
    "    img = mpimg.imread(folder_loc + '/train/images/' + (6 - len(str(image_id))) * str(0) + str(image_id) + '.jpg')\n",
    "    \n",
    "    #display image\n",
    "    img_plot = plt.imshow(image)\n",
    "    \n",
    "    #loading image id\n",
    "    annotations = coco_train.loadAnns(coco_train.getAnnIds(imgIds=image_id))\n",
    "\n",
    "    for i in range(len(annotations)):\n",
    "        #different color for different annotations\n",
    "        colors = ['b', 'c', 'r', 'g', 'm', 'y', 'k'][i]\n",
    "        ann = annotations[i]\n",
    "\n",
    "        #plotting segmentation\n",
    "        for seg in ann['segmentation']:\n",
    "              plt.fill(seg[0::2], seg[1::2], colors, alpha=0.4)\n",
    "              plt.fill(seg[0::2], seg[1::2], colors, alpha=0.8)\n",
    "  \n",
    "    #show results\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the first 5 images with the segmentation\n",
    "img_num = []\n",
    "for i in range(5):\n",
    "    img_num.append(coco_train.getImgIds()[i])\n",
    "for ids in img_num:\n",
    "    plot_image(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13800,
     "status": "ok",
     "timestamp": 1616495461586,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "ISNEFP1rZijF",
    "outputId": "d778b408-d002-4587-925d-b18a3713ab67"
   },
   "outputs": [],
   "source": [
    "catIds_raw = coco_train.getCatIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12853,
     "status": "ok",
     "timestamp": 1616495461588,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "hA7UxQARy_kv",
    "outputId": "338b6b1a-faf7-47a5-88ef-270e54960e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO categories:  273\n"
     ]
    }
   ],
   "source": [
    "# display COCO categories\n",
    "categories = coco_train.loadCats(coco_train.getCatIds())\n",
    "names=[cat['name'] for cat in categories]\n",
    "print('COCO categories: ', len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 11202,
     "status": "ok",
     "timestamp": 1616495461591,
     "user": {
      "displayName": "Riccardo FAVA",
      "photoUrl": "",
      "userId": "11623424237951354674"
     },
     "user_tz": -60
    },
    "id": "NHe8tzXzbNAx"
   },
   "outputs": [],
   "source": [
    "catIds = []\n",
    "\n",
    "for cat in catIds_raw:\n",
    "  catIds.append([len(coco_train.getImgIds(catIds=cat)), cat])\n",
    "\n",
    "catIds.sort()\n",
    "cat_ids = [cat_num[1] for cat_num in catIds ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing the data for the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_not_saved = not (os.path.exists(folder_loc + 'x_train.npy') and os.path.exists(folder_loc + 'y_train.npy'))\n",
    "#val_data_not_saved = not (os.path.exists(folder_loc + 'x_val.npy') and os.path.exists(folder_loc + 'y_val.npy'))\n",
    "\n",
    "train_data_not_saved = not (os.path.exists(folder_loc + 'y_train.npy'))\n",
    "val_data_not_saved = not (os.path.exists(folder_loc + 'y_val.npy'))\n",
    "\n",
    "#size that image are resize to\n",
    "image_size = 256\n",
    "\n",
    "#number of classes / images\n",
    "num_classes = len(catIds_raw) + 1\n",
    "num_images_train = len(coco_train.getImgIds())\n",
    "num_images_val = len(coco_val.getImgIds())\n",
    "\n",
    "#Run only if data needs to be saved\n",
    "if train_data_not_saved:\n",
    "  \n",
    "  #Creating blank X and blank Y\n",
    "  X_train = np.zeros((num_images_train, image_size, image_size, 3))\n",
    "  Y_train = np.zeros((num_images_train, image_size, image_size, 1))\n",
    "\n",
    "  #iterating through train images\n",
    "  for i in range(num_images_train):\n",
    "\n",
    "    #printing how far in the iteration\n",
    "    print(str(i+1) + '/' + str(num_images_train))\n",
    "\n",
    "    #current image\n",
    "    image = coco_train.getImgIds()[i]\n",
    "    #load annotations\n",
    "    annotations = coco_train.loadAnns(coco_train.getAnnIds(imgIds=image))\n",
    "    #creating a matrix of zeros to store annotations\n",
    "    mask = np.zeros((coco_train.imgs[image]['height'], coco_train.imgs[image]['width'], 1))\n",
    "\n",
    "    for ann in annotations:\n",
    "\n",
    "      #determining class by index in the cat_ids list\n",
    "      ann_class = cat_ids.index(ann['category_id']) + 1\n",
    "      #filling zeros matrix with appropriate class\n",
    "      #when there is multiclass overlap more common class wins since we sorted above\n",
    "      mask[:, :, 0] = np.maximum(mask[:, :, 0], coco_train.annToMask(ann) * ann_class)\n",
    "    \n",
    "    #resizing image\n",
    "    mask = tf.image.resize(mask, (image_size, image_size))\n",
    "    Y_train[i] = mask\n",
    "\n",
    "  #Saving results\n",
    "  np.save(arr=Y_train, file=folder_loc + 'y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5LiALU5D1_w0"
   },
   "outputs": [],
   "source": [
    "#Run only if data needs to be saved\n",
    "if val_data_not_saved:\n",
    "\n",
    "  #Creating blank X and blank Y\n",
    "  X_val = np.zeros((num_images_val, image_size, image_size, 3))\n",
    "  Y_val = np.zeros((num_images_val, image_size, image_size, 1))\n",
    "\n",
    "\n",
    "  #iterating through train images\n",
    "  for i in range(num_images_val):\n",
    "    \n",
    "    #print(str(i+1) + '/' + str(num_images_train))\n",
    "\n",
    "    #current image\n",
    "    image = coco_val.getImgIds()[i]\n",
    "    #load annotations\n",
    "    annotations = coco_val.loadAnns(coco_val.getAnnIds(imgIds=image))\n",
    "    #creating a matrix of zeros to store annotations\n",
    "    mask = np.zeros((coco_val.imgs[image]['height'], coco_val.imgs[image]['width'], 1))\n",
    "\n",
    "    for ann in annotations:\n",
    "\n",
    "      #determining class by index in the cat_ids list\n",
    "      ann_class = cat_ids.index(ann['category_id']) + 1\n",
    "      #filling zeros matrix with appropriate class\n",
    "      #when there is multiclass overlap more common class wins since we sorted above\n",
    "      mask[:, :, 0] = np.maximum(mask[:, :, 0], coco_val.annToMask(ann) * ann_class)\n",
    "    \n",
    "    #resizing image\n",
    "    mask = tf.image.resize(mask, (image_size, image_size))\n",
    "    Y_val[i] = mask\n",
    "  \n",
    "  #Saving results\n",
    "  np.save(arr=Y_val, file=folder_loc + 'y_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Food_recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
